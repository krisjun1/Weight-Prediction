trainPC<-predict(preProc, log10(training[,-58]+1))
modelFit<-train(training$type~., method="glm", data = trainPC)
testPC<-predict(preProc, log10(testing[,-58]+1))
confusionMatrix(testing$type, predict(modelFit, testPC))
library(caret); data("faithful"); set.seed(333)
inTrain<-createDataPartition(y=faithful$waiting, p=0.5, list = FALSE)
trainFaith<-faithful[inTrain,]; testFaith<-faithful[-inTrain,]
head(trainFaith)
plot(trainFaith$waiting, trainFaith$eruptions, pch=19, col="blue", xlab="waiting", ylab="Duration")
lm1<-lm(eruutions~waiting, data = trainFaith)
lm1<-lm(erutions~waiting, data = trainFaith)
lm1<-lm(eruptions~waiting, data = trainFaith)
summary(lm1)
plot(trainFaith$waiting, trainFaith$eruptions, pch=19, col="blue", xlab="waiting", ylab="Duration")
lines(trainFaith$waiting, lm1$fitted, lwd=3)
coef(lm1)[1]+coef(lm1)[2]*80
newdata<-data.frame(waiting=80)
predict(lm1, newdata)
par(mfrow=c(1,2))
plot(trainFaith$waiting, trainFaith$eruptions, pch=19, col="blue",xlab="waiting", ylab="Duration")
lines(trainFaith$waiting, predict(lm1), lwd=3)
plot(testFaith$waiting, testFaith$eruptions, pch=19, col="blue",xlab="waiting", ylab="Duration")
lines(testFaith$waiting, predict(lm1, newdata=testFaith), lwd=3)
sqrt(sum((lm1$fitted-trainFaith$eruptions)^2))
sqrt(sum((predict(lm1, newdata=testFaith)-testFaith$eruptions)^2))
pred1<-predict(lm1, newdata=testFaith, interval="prediction")
ord<-order(testFaith$waiting)
plot(testFaith$waiting,testFaith$eruptions, pch=19, col="blue")
matlines(testFaith$waiting[ord], pred1[ord,], type = "l", col = c(1,2,2), lty = c(1,1,1), lwd = 3)
modelFit<-train(eruptions~waiting, data = trainFaith, method="lm")
summary(modelFit$finalModel)
library(ISLR); library(ggplot2); library(caret);
data("Wage")
dim(Wage)
head(Wage)
Wage<-subset(Wage, select = c(logwage))
dim(Wage)
summary(Wage)
data("Wage")
Wage<-subset(Wage, select = -c(logwage))
summary(Wage)
inTrain<-createDataPartition(y=Wage$wage, p=0.7, list = FALSE)
training<-Wage[inTrain,]
testing<-Wage[-inTrain,]
dim(training); dim(testing)
featurePlot(x=training[,c("age","education","jobclass")], y=training$wage, plot = "pairs")
qplot(age, wage, data = training)
qplot(age, wage,color=jobclass, data = training)
qplot(age, wage,color=education, data = training)
modelFit<-train(wage~age+jobclass+education, method="lm", data = training)
finMod<-modelFit$finalModel
print(modelFit)
plot(finMod,1,pch=19, cex=0.5, col="#00000010")
plot(finMod,1,pch=19, cex=0.5, col="#00000010")
qplot(finMod$fitted, finMod$residuals, color=race, data = training)
plot(finMod$residuals, pch=19)
plot(finMod$residuals, pch=19)
pred<-predict(modelFit, testing)
qplot(wage, pred, color=year, data=testing)
modFit<-train(wage~., data = training, method="lm")
pred<-predict(modFit,testing)
qplot(wage, pred, data = testing)
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(concrete)
head(concrete)
dim(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
names(training)
dim(training); dim(testing)
dim(mixtures)
head(mixtures)
featurePlot(x=training[,-c("CompressiveStrength")], y=training$CompressiveStrength, plot = "pairs")
featurePlot(x=training[,-c(CompressiveStrength)], y=training$CompressiveStrength, plot = "pairs")
featurePlot(x=training[,-"CompressiveStrength"], y=training$CompressiveStrength, plot = "pairs")
featurePlot(x=training[, names(training)[1:8]], y=training$CompressiveStrength, plot = "pairs")
histogram(mixtures$Superplasticizer)
histogram(concrete$Superplasticizer)
histogram(log10(mixtures$Superplasticizer+1))
concrete$Superplasticizer
x<-concrete$Superplasticizer
x[1:100]
x[100:200]
x[200:300]
x[300:400]
x[400:500]
x[500:600]
x[600:700]
x[700:800]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
data(AlzheimerDisease)
dim(AlzheimerDisease)
library(AppliedPredictiveModeling)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
set.seed(3433)data(AlzheimerDisease)
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
library(caret)
library(ggplot2)
library(lattice)
library(caret)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(training)
head(training)[,59:69]
preProc<-preProcess(training[,59:69], method = "pca", pcaComp = 2)
trainPC<-predict(preProc, training[,59:69])
preProc$std
(preProc$std)^2
preProc$numComp
preProc<-preProcess(training[,59:69], method = "pca", thresh = .8)
preProc$numComp
preProc<-preProcess(training[,58:69], method = "pca", thresh = .8)
preProc$numComp
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainingIL<-training[,c("diagnosis", 58:69)]
names(training)[1]
trainingIL<-training[,58:69]
trainingIL$diagnosis<-training$diagnosis
dim(trainingIL)
names(trainingIL)
modelFit1<-train(diagnosis~., data = trainingIL, method="glm")
preProc<-preProcess(trainingIL[,-13], method = "pca", thresh = 0.8)
trainPC<-predict(preProc, trainingIL[,-13])
modelFit2<-train(trainingIL$diagnosis~., method="glm", data = trainPC)
testingIL<-testing[,58:69]
testingIL$diagnosis<-testing$diagnosis
dim(testingIL)
confusionMatrix(testingIL$diagnosis, predict(modelFit1, testingIL[,-13]))
data("iris")
library(ggplot2)
names(iris)
table(iris$Species)
library(caret)
library(lattice)
library(caret)
inTrain<-createDataPartition(y=iris$Species, p=0.7,list = FALSE)
training<-iris[inTrain,]
testing<-iris[-inTrain,]
dim(training); dim(testing)
qplot(Petal.Width, Sepal.Width, color=Species, data = training)
modFit<-train(Species~., method="rpart", data = training)
modFit<-train(Species~., method="rpart", data = training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE, main="Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex=.8)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
predict(modFit, newdata = testing)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data("ozone", package = "ElemStatLearn")
ozone<-head(ozone)
ozone<-ozone[order(ozone$ozone)]
ozone<-ozone[order(ozone$ozone),]
head(ozone)
package_version("AppliedPredictiveModeling")
packageVersion("AppliedPredictiveModeling")
packageVersion("caret")
packageVersion("ElemStatLearn")
install.packages("pgmm")
packageVersion("pgmm")
packageVersion("rpart")
library(AppliedPredictiveModeling)
data("segmentationOriginal")
library(caret)
library(caret)
dim(segmentationOriginal)
names(segmentationOriginal)
inTrain<-createDataPartition(y=segmentationOriginal$Case, p=0.7, list = FALSE)
training<-segmentationOriginal[inTrain,]
testing<-segmentationOriginal[-inTrain,]
dim(training); dim(testing)
set.seed(125)
library(rpart)
modFit<-train(Case~., method="rpart", data = training)
set.seed(125)
modFit<-train(Case~., method="rpart", data = training)
print(modFit$finalModel)
training[,2][1:5]
segmentationOriginal[,2][1:5]
modFit
head(training)[1:10]
set.seed(125)
modFit<-train(Class~., method="rpart", data = training)
modFit$finalModel
library(rattle)
library(AppliedPredictiveModeling)
data("segmentationOriginal")
library(caret)
library(rpart)
training<-segmentationOriginal[segmentationOriginal$Case=="Training",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Testing",]
dim(training); dim(testing)
dim(training); dim(testing)
dim(segmentationOriginal)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
dim(train); dim(test)
dim(training); dim(testing)
dim(segmentationOriginal)
set.seed(125)
modFit<-train(Class~., method="rpart", data = training)
print(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
library(AppliedPredictiveModeling)
data("segmentationOriginal")
library(caret)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
dim(segmentationOriginal)
names(segmentationOriginal)[1:5]
segmentationOriginal[,2][1:5]
dim(training); dim(testing)
library(rpart)
set.seed(125)
fitMod<-train(Class~., method="rpart", data = training)
print(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(fitMod$finalModel)
library(pgmm)
data("olive")
dim(olive)
names(olive)
head(olive)
olive<-olive[,-1]
head(olive)
tail(olive)
modFit<-train(Area~., method="rpart", data = olive)
plot(modFit$finalModel, uniform = TRUE, main="Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex=0.8)
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit, newdata = newdata)
library(ElemStatLearn)
data("SAheart")
dim(SAheart)
names(SAheart)
head(SAheart)
tail(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
?glm
set.seed(13234)
trainFit<-glm(chd~age+alcohol+obesity+tobacco+typea+ldl, data = trainSA, family = "binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass()
missClass
summary(trainFit)
prediction<-predict(trainFit)
length(prediction)
prediction
values<-trainSA[,10]
length(values)
values
x<-trainFit$fitted.values
length(x)
x
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
misClass
mc<- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
mc
mc<- sum(((prediction > 0.5)*1) != values)/length(values)
mc
set.seed(13234)
testFit<-glm(chd~age+alcohol+obesity+tobacco+typea+ldl, data = testSA, family = "binomial")
prediction<-predict(testFit)
values<-testSA[,10]
mc2<- sum(((prediction > 0.5)*1) != values)/length(values)
mc2
prediction<-predict(trainFit, newdata = testSA)
mc2<- sum(((prediction > 0.5)*1) != values)/length(values)
mc2
set.seed(13234)
library(caret)
set.seed(13234)
dim(trainSA)
dim(testSA)
?train
library(caret)
modSA<-train(chd~age+alcohol+obesity+tobacco+typea+ldl, method="glm", family="binomial", data=trainSA)
names(trainSA)
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
library(caret)
library(ElemStatLearn)
data("SAheart")
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
library(caret)
library(caret)
library(ElemStatLearn)
data("SAheart")
set.seed(8484)
inTrain = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA<-SAheart[inTrain,]
testSA<-SAheart[-inTrain,]
dim(trainSA); dim(testSA)
set.seed(13234)
modSA<-train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method="glm", family="binomial", data = trainSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd, prediction = predict(modSA))
missClass(testSA$chd, prediction = predict(modSA, newdata = testSA))
library(ElemStatLearn)
data("vowel.train")
data("vowel.test")
dim(vowel.test)
dim(vowel.train)
names(vowel.test)
names(vowel.train)
head(vowel.test)
head(vowel.train)
vowel.test$y<-factor(vowel.test$y)
vowel.train$y<-factor(vowel.train$y)
set.seed(33833)
modFit<-train(y~., data = vowel.train, mathod="rf", prox=TRUE)
varImp(modFit)
randomForest(modFit)
set.seed(33833)
modFit<-train(y~., data = vowel.train, mathod="rf", prox=TRUE)
varImp(modFit)
?randomForest
library(ElemStatLearn)
data("vowel.test")
data("vowel.train")
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test)
vowel.test$y<-as.factor(vowel.test$y)
install.packages("randomForest")
install.packages("randomForest")
library(randomForest)
modFit<-randomForest(y~., data = vowel.train)
varImp(modFit)
order(varImp(modFit), decreasing = TRUE)
modFit2<-train(y~., data = vowel.train, mathod="rf", prox=TRUE)
varImp(modFit2)
library(shiny)
runApp('Google Drive/Data Science/Developing Data Products/Week1/ShinyApps/PracticeApp')
runApp('Google Drive/Data Science/Developing Data Products/Week1/ShinyApps/Practice2App')
runApp('Google Drive/Data Science/Developing Data Products/Week1/ShinyApps/Practice2App')
runApp('Google Drive/Data Science/Developing Data Products/Week1/ShinyApps/PracticeApp')
runApp('Google Drive/Data Science/Developing Data Products/Week1/ShinyApps/Practice2App')
runApp('Google Drive/Data Science/Developing Data Products/Week1/ShinyApps/Practice2App')
runApp('Google Drive/Data Science/Developing Data Products/Week1/ShinyApps/PracticeApp')
runApp('Google Drive/Data Science/Developing Data Products/Week1/ShinyApps/Practice2App')
install.packages("plotly")
library(plotly)
plot_ly(mtcars, x=wt, y=mpg, mode="marker")
head(mtcars)
plot_ly(mtcars, x = wt, y = mpg, mode = "marker")
plot_ly(mtcars, x = wt, y = mpg, mode = "markers")
plot_ly(mtcars, x = ~wt, y=~mpg, type = "scatter")
plot_ly(mtcars, x = ~wt, y=~mpg, mode="markers")
plot_ly(mtcars, x = ~wt, y=~mpg, type = "scatter")
plot_ly(mtcars, x = ~wt, y=~mpg, type = "scatter", color = as.factor(cyl))
plot_ly(mtcars, x = ~wt, y=~mpg, type = "scatter", color = as.factor(~cyl))
plot_ly(mtcars, x = ~wt, y=~mpg, type = "scatter", color = as.factor("cyl"))
plot_ly(mtcars, x = ~wt, y=~mpg, type = "scatter", color = ~as.factor(cyl))
plot_ly(mtcars, x = ~wt, y=~mpg, type = "scatter", color = ~as.factor(cyl), size = ~hp)
set.seed(2016-07-21)
temp<-rnorm(100, mean = 30, sd=5)
pressure<-rnorm(100)
dtime<-1:100
plot_ly(x=~temp, y=~pressure, z=~dtime, )
plot_ly(x=~temp, y=~pressure, z=~dtime, type = "scatter3d", color = ~temp)
data("airmiles")
head(airmiles)
dim(airmiles)
length(airmiles)
airmiles
plot_ly(x~time(airmiles), y=~airmiles, type = "scatter")
time(airmiles)
plot_ly(airmiles, x=time(airmiles), y=airmiles, type = "scatter")
plot_ly(x=time(airmiles), y=airmiles, type = "scatter")
plot_ly(x=time(airmiles), y=airmiles)
library(plotly)
library(tidyr)
library(dplyr)
data("EuStockMarkets")
EuStockMarkets
head(EuStockMarkets)
stocks<-as.data.frame(EuStockMarkets) %>% gather(index, price) %>% mutate(time=rep(time(EuStockMarkets), 4))
dim(stocks)
plot_ly(stocks, x=~time, y=~price, color = ~index, type = "scatter")
plot_ly(stocks, x=~time, y=~price, color = ~index)
plot_ly(stocks, x=time, y=price, color = index)
plot_ly(stocks, x=~time, y=~price, color = ~index)
plot_ly(x=~precip, type = "histogram")
plot_ly(iris, y=~Petal.Length, color = ~Species, type = "boxplot")
plot_ly(iris, y=~Petal.Length, color = ~Species, type = "box")
terrain1<-matrix(rnorm(100*100), nrow = 100, ncol = 100)
plot_ly(z=~terrain1, type = "heatmap")
terrain2<-matrix(sort(rnorm(100*100)), nrow = 100, ncol = 100)
plot_ly(z=~terrain1, type = "surface")
plot_ly(z=~terrain2, type = "surface")
plot_ly(z=~terrain2, type = "surface")
state_pop<-data.frame(State=state.abb, Pop=as.vector(state.x77[,1]))
head(state_pop)
state_pop$hover<-with(state_pop, paste(State, "<br>", "Population:", pop))
state_pop$hover<-with(state_pop, paste(State, "<br>", "Population:", Pop))
head(state_pop)
boarders<-list(color=toRGB("red"))
map_options<-list(scope="usa", projection=list(type="albers usa"), showlakes=TRUE, lakecolor=toRGB("white"))
plot_ly(z=~state_pop$Pop, text=~state_pop$hover, locations= ~state_pop$State, type = "choropleth", locationmode="USA-states", color = state_pop$Pop, colors = "Blues", marker= list(line=borders)) %>% layout(title="US Population in 1975", geo=map_options)
shiny::runApp('Google Drive/Data Science/09_Developing Data Products/Week1/ShinyApps/Practice2App')
runApp('Google Drive/Data Science/09_Developing Data Products/Week1/ShinyApps/Practice2App')
pickXY(my_data)
knitr::opts_chunk$set(echo = FALSE)
head(mtcars)
knitr::opts_chunk$set(echo = FALSE)
head(mtcars)
install.packages("leaflet")
library(leaflet)
knitr::opts_chunk$set(echo = TRUE)
library(leaflet)
my_map<-leaflet() %>%
addTiles()
my_map
library(leaflet)
my_map<-leaflet() %>%
addTiles()
my_map
library(leaflet)
my_map<-leaflet() %>%
addTiles()
my_map
library(leaflet)
my_map<-leaflet() %>% addTiles()
my_map
my_map<-leaflet() %>%
addTiles() %>%
addMarkers(lat=33.327461, lng=-105.661413, popupOptions = "Krishna's Apt")
my_map
my_map<-leaflet() %>%
addTiles() %>%
addMarkers(lat=33.327461, lng=-105.661413, popup = "Krishna's Apt")
my_map
set.seed(2016-04-25)
df<-data.frame(lat= runif(20, min = 39.2, max = 39.3),
lng= runif(20, min = -76.6, max = -76.5))
df %>%
leaflet() %>%
addTiles() %>%
addMarkers()
df %>%
leaflet() %>%
addTiles() %>%
addMarkers()
set.seed(2016-04-25)
df<-data.frame(lat= runif(500, min = 39.2, max = 39.3),
lng= runif(500, min = -76.6, max = -76.5))
head(df)
dim(df)
df %>%
leaflet() %>%
addTiles() %>%
addMarkers(clusterOptions=markerClusterOptions())
setwd("~/Google Drive/Data Science/09_Developing Data Products/Week4/Project")
data_f<-read.csv(enmuf)
list.files()
data_f<-read.csv("enmuf.csv")
dim(data_f)
head(data_f)
data_m<-read.csv("enmum.csv")
dim(data_m)
head(data_m)
data_fm<-read.csv("enmu.csv")
dim(data_fm)
head(data_fm)
shiny::runApp('~/Google Drive/Data Science/Developing Data Products/Week1/ShinyApps/Weight_Prediction')
runApp('~/Google Drive/Data Science/Developing Data Products/Week1/ShinyApps/Weight_Prediction')
runApp('~/Google Drive/Data Science/Developing Data Products/Week1/ShinyApps/Weight_Prediction')
runApp('~/Google Drive/Data Science/Developing Data Products/Week1/ShinyApps/Weight_Prediction')
runApp('~/Google Drive/Data Science/Developing Data Products/Week1/ShinyApps/Weight_Prediction')
runApp('~/Google Drive/Data Science/Developing Data Products/Week1/ShinyApps/Weight_Prediction')
